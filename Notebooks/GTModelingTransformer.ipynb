{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfc9de7-5595-4f14-9f4f-639e0507e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files for label encoders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:23<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoders saved to label_encoders.pkl\n",
      "Generating .pt sub-chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [01:47<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete: 1840 sub-chunks saved to preprocessed_chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TERRAIN TRANSFORMER - OPTIMIZED FOR SPEED ON RTX 4070 WITH PREPROCESSED DATA\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = 'block_dataset'  # CSV files\n",
    "OUT_DIR = 'preprocessed_chunks'  # Output .pt files\n",
    "ENCODER_PATH = 'label_encoders.pkl'\n",
    "CHUNK_WIDTH, CHUNK_HEIGHT, CHUNK_DEPTH = 16, 256, 16\n",
    "\n",
    "# Make sure this agrees with the modeling script\n",
    "# If we want to keep Java unchanged we gotta make it 256\n",
    "SUB_CHUNK_HEIGHT = 32 \n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Categorical fields\n",
    "categorical_fields = [\n",
    "    'Block_ID',\n",
    "    'Block_to_Left', 'Block_to_Right',\n",
    "    'Block_Below', 'Block_Above',\n",
    "    'Block_in_Front', 'Block_Behind',\n",
    "    'ChunkBiome', 'Biome'\n",
    "]\n",
    "\n",
    "# Collect all unique values for encoders\n",
    "label_encoders = {field: LabelEncoder() for field in categorical_fields}\n",
    "all_values = {field: set() for field in categorical_fields}\n",
    "\n",
    "csv_files = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith('.csv')]\n",
    "\n",
    "# Pass 1: Collect unique values\n",
    "print(\"Scanning files for label encoders...\")\n",
    "for file in tqdm(csv_files):\n",
    "    df = pd.read_csv(file)\n",
    "    for field in categorical_fields:\n",
    "        all_values[field].update(df[field].dropna().unique())\n",
    "\n",
    "for field in categorical_fields:\n",
    "    label_encoders[field].fit(list(all_values[field]))\n",
    "\n",
    "# Save encoders\n",
    "with open(ENCODER_PATH, 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "print(f\"Label encoders saved to {ENCODER_PATH}\")\n",
    "\n",
    "# Pass 2: Generate .pt subchunks\n",
    "print(\"Generating .pt sub-chunks...\")\n",
    "file_count = 0\n",
    "for file in tqdm(csv_files):\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Filter invalid rows early\n",
    "    df = df[(df['x'] < CHUNK_WIDTH) & (df['y'] < CHUNK_HEIGHT) & (df['z'] < CHUNK_DEPTH)]\n",
    "\n",
    "    # Normalize light\n",
    "    df['Light_Level'] = df['Light_Level'] / 15.0\n",
    "\n",
    "    # Encode categorical features\n",
    "    for key in categorical_fields:\n",
    "        df[key] = label_encoders[key].transform(df[key])\n",
    "\n",
    "    # Iterate over vertical slices\n",
    "    for y_start in range(0, CHUNK_HEIGHT, SUB_CHUNK_HEIGHT):\n",
    "        y_end = y_start + SUB_CHUNK_HEIGHT\n",
    "        sub_df = df[(df['y'] >= y_start) & (df['y'] < y_end)]\n",
    "\n",
    "        # Initialize tensors\n",
    "        input_tensor = np.zeros((CHUNK_WIDTH, SUB_CHUNK_HEIGHT, CHUNK_DEPTH, 10), dtype=np.float32)\n",
    "        output_tensor = np.full((CHUNK_WIDTH, SUB_CHUNK_HEIGHT, CHUNK_DEPTH), -1, dtype=np.int64)\n",
    "\n",
    "        for row in sub_df.itertuples(index=False):\n",
    "            x, y, z = int(row.x), int(row.y) - y_start, int(row.z)\n",
    "            if 0 <= x < CHUNK_WIDTH and 0 <= y < SUB_CHUNK_HEIGHT and 0 <= z < CHUNK_DEPTH:\n",
    "                features = [\n",
    "                    row.ChunkBiome, row.Biome,\n",
    "                    float(row.Is_Surface), float(row.Light_Level),\n",
    "                    row.Block_to_Left, row.Block_to_Right,\n",
    "                    row.Block_Below, row.Block_Above,\n",
    "                    row.Block_in_Front, row.Block_Behind,\n",
    "                ]\n",
    "                input_tensor[x, y, z] = features\n",
    "                output_tensor[x, y, z] = row.Block_ID\n",
    "\n",
    "        # Save to disk\n",
    "        input_tensor = torch.tensor(input_tensor).permute(3, 0, 1, 2)  # [C, X, Y, Z]\n",
    "        output_tensor = torch.tensor(output_tensor)  # [X, Y, Z]\n",
    "\n",
    "        chunk_name = os.path.basename(file).replace('.csv', f'_Y{y_start}.pt')\n",
    "        torch.save((input_tensor, output_tensor), os.path.join(OUT_DIR, chunk_name))\n",
    "        file_count += 1\n",
    "\n",
    "print(f\"✅ Preprocessing complete: {file_count} sub-chunks saved to {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53787de2-b1ef-4116-87e6-50f122fee380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 276/276 [00:19<00:00, 14.47it/s]\n",
      "Epoch 1 [Valid]: 100%|██████████| 31/31 [00:01<00:00, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 5.0119 | Val Loss: 4.7796\n",
      "Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 276/276 [00:06<00:00, 42.77it/s]\n",
      "Epoch 2 [Valid]: 100%|██████████| 31/31 [00:00<00:00, 87.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 4.4499 | Val Loss: 3.7282\n",
      "Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 276/276 [00:06<00:00, 43.64it/s]\n",
      "Epoch 3 [Valid]: 100%|██████████| 31/31 [00:00<00:00, 87.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 3.4710 | Val Loss: 3.0644\n",
      "Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|██████████| 276/276 [00:06<00:00, 43.35it/s]\n",
      "Epoch 4 [Valid]: 100%|██████████| 31/31 [00:00<00:00, 87.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 2.9625 | Val Loss: 2.6852\n",
      "Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|██████████| 276/276 [00:06<00:00, 43.58it/s]\n",
      "Epoch 5 [Valid]: 100%|██████████| 31/31 [00:00<00:00, 87.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 2.6657 | Val Loss: 2.5451\n",
      "Saved best model\n",
      "Exported to ONNX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "DATA_DIR = 'preprocessed_chunks'  # Use preprocessed .pt files\n",
    "LABEL_ENCODER_PATH = 'label_encoders.pkl'\n",
    "CHUNK_WIDTH, CHUNK_HEIGHT, CHUNK_DEPTH = 16, 256, 16\n",
    "SUB_CHUNK_HEIGHT = 32\n",
    "BATCH_SIZE = 6\n",
    "EMBED_DIM = 80\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 5\n",
    "USE_AMP = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === DATASET ===\n",
    "class PreprocessedChunkDataset(Dataset):\n",
    "    def __init__(self, files, training=True):\n",
    "        self.files = files\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            x, y = torch.load(self.files[idx], weights_only=True)\n",
    "            if self.training and torch.rand(1).item() > 0.5:\n",
    "                if torch.rand(1).item() > 0.5:\n",
    "                    x = torch.flip(x, [1])\n",
    "                    y = torch.flip(y, [0])\n",
    "                if torch.rand(1).item() > 0.5:\n",
    "                    x = torch.flip(x, [3])\n",
    "                    y = torch.flip(y, [2])\n",
    "            return x, y\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed loading {self.files[idx]}: {e}\")\n",
    "            return torch.zeros((10, CHUNK_WIDTH, SUB_CHUNK_HEIGHT, CHUNK_DEPTH)), torch.full((CHUNK_WIDTH, SUB_CHUNK_HEIGHT, CHUNK_DEPTH), -1)\n",
    "\n",
    "# === POSITIONAL ENCODING ===\n",
    "class FastPositionalEncoding3D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv_pos = nn.Conv3d(3, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, X, Y, Z = x.shape\n",
    "        pos_x = torch.linspace(0, 1, X, device=x.device)\n",
    "        pos_y = torch.linspace(0, 1, Y, device=x.device)\n",
    "        pos_z = torch.linspace(0, 1, Z, device=x.device)\n",
    "        grid_x, grid_y, grid_z = torch.meshgrid(pos_x, pos_y, pos_z, indexing='ij')\n",
    "        pos = torch.stack([grid_x, grid_y, grid_z], dim=0).unsqueeze(0).expand(B, -1, -1, -1, -1)\n",
    "        return x + self.conv_pos(pos)\n",
    "\n",
    "# === ATTENTION BLOCK ===\n",
    "class FastAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(4, dim)\n",
    "        self.spatial_mixer = nn.Sequential(\n",
    "            nn.Conv3d(dim, dim, 3, padding=1, groups=dim), nn.GELU(), nn.Conv3d(dim, dim, 1)\n",
    "        )\n",
    "        self.channel_mixer = nn.Sequential(\n",
    "            nn.Conv3d(dim, dim*2, 1), nn.GELU(), nn.Conv3d(dim*2, dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = self.norm(x)\n",
    "        x = x + self.spatial_mixer(x_norm)\n",
    "        x = x + self.channel_mixer(self.norm(x))\n",
    "        return x\n",
    "\n",
    "# === MODEL ===\n",
    "class FastTerrainTransformer(nn.Module):\n",
    "    def __init__(self, in_channels, embed_dim, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, embed_dim, 3, padding=1), nn.GELU()\n",
    "        )\n",
    "        self.pos_encoding = FastPositionalEncoding3D(embed_dim)\n",
    "        self.blocks = nn.ModuleList([FastAttentionBlock(embed_dim) for _ in range(num_layers)])\n",
    "        self.output = nn.Sequential(\n",
    "            nn.GroupNorm(4, embed_dim), nn.Conv3d(embed_dim, num_classes, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return self.output(x)\n",
    "\n",
    "# === LOAD LABEL ENCODERS ===\n",
    "with open(LABEL_ENCODER_PATH, 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoders['Block_ID'].classes_)\n",
    "\n",
    "# === LOAD DATA ===\n",
    "all_files = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith('.pt')]\n",
    "val_split = 0.1\n",
    "val_count = int(len(all_files) * val_split)\n",
    "train_files = all_files[val_count:]\n",
    "val_files = all_files[:val_count]\n",
    "\n",
    "train_ds = PreprocessedChunkDataset(train_files, training=True)\n",
    "val_ds = PreprocessedChunkDataset(val_files, training=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# === TRAIN ===\n",
    "model = FastTerrainTransformer(10, EMBED_DIM, NUM_LAYERS, num_classes).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "scaler = torch.amp.GradScaler('cuda' if USE_AMP and device.type == 'cuda' else 'cpu')\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=USE_AMP):\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits.view(-1, num_classes), batch_y.view(-1))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Valid]\"):\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits.view(-1, num_classes), batch_y.view(-1))\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'terrain_transformer_2.pth')\n",
    "        print(\"Saved best model\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{PATIENCE}\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# Export ONNX\n",
    "model.eval().to('cpu')\n",
    "dummy = torch.randn(1, 10, CHUNK_WIDTH, SUB_CHUNK_HEIGHT, CHUNK_DEPTH)\n",
    "torch.onnx.export(model, dummy, 'terrain_transformer_model.onnx', input_names=['input'], output_names=['output'], dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}}, verbose=False)\n",
    "print(\"Exported to ONNX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a819c4dd-0fa6-49ad-8220-d31eaed517b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved block_id_mapping.json\n",
      "Saved biome_id_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# === EXPORT BLOCK AND BIOME MAPPINGS ===\n",
    "block_id_mapping = {\n",
    "    int(i): label_encoders['Block_ID'].classes_[i]\n",
    "    for i in range(len(label_encoders['Block_ID'].classes_))\n",
    "}\n",
    "with open('block_id_mapping.json', 'w') as f:\n",
    "    json.dump(block_id_mapping, f, indent=2)\n",
    "print(\"Saved block_id_mapping.json\")\n",
    "\n",
    "biome_mapping = {\n",
    "    label_encoders['ChunkBiome'].classes_[i]: int(i)\n",
    "    for i in range(len(label_encoders['ChunkBiome'].classes_))\n",
    "}\n",
    "with open('biome_id_mapping.json', 'w') as f:\n",
    "    json.dump(biome_mapping, f, indent=2)\n",
    "print(\"Saved biome_id_mapping.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
